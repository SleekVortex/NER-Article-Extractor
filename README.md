# Распознавание артикулов из описаний товаров

Этот проект посвящен распознаванию артикулов товаров из их текстовых описаний с использованием методов обработки естественного языка (NLP) и моделей машинного обучения.

## Структура проекта

- **LLM_model.ipynb**: Содержит код для обучения легкой модели LLM для распознавания артикулов.
- **BERT_Train.ipynb**: Содержит код для обучения модели BERT для задачи распознавания именованных сущностей (NER).
- **model_comparison.ipynb**: Сравнивает производительность модели LLM и модели на основе BERT с помощью различных метрик.

### Данные

Проект использует датасет excel с описанием товаров и их артикулами.

## Обучение модели LLM

В ноутбуке `LLM_model.ipynb` выполнены следующие шаги:

1. **Подготовка данных**: Загрузка датасета и подготовка инструкций для модели LLM.
2. **Обучение модели**: Использование легкой предобученной модели и её дообучение на датасете.
3. **Оценка модели**: Оценка производительности модели на тестовом наборе данных.
4. **Развертывание модели**: Сохранение дообученной модели и настройка сервера Ollama для её обслуживания.

## Обучение модели BERT

В ноутбуке `BERT_Train.ipynb` выполнены следующие шаги:

1. **Подготовка данных**: Загрузка датасета и аннотирование текста с сущностями.
2. **Обучение модели**: Обучение модели BERT на аннотированном датасете.
3. **Тюнинг гиперпараметров**: Предоставлен шаблон для тюнинга гиперпараметров с использованием Optuna.
4. **Оценка модели**: Оценка производительности модели на тестовом наборе данных.

## Сравнение моделей

В ноутбуке `model_comparison.ipynb` сравниваются модели LLM и BERT по следующим метрикам:

- Среднее расстояние Левенштейна
- Среднее косинусное сходство
- Точность совпадений

## Используемые модели и стек технологий

- **LLM**: Используется модель `unsloth/Phi-3.5-mini-instruct`, которая является легкой и предобученной на русском языке.
- **BERT**: Используются модели `cointegrated/rubert-tiny2` и `ai-forever/sbert_large_nlu_ru` для задачи распознавания именованных сущностей.
- **Стек технологий**: Python, Jupyter Notebooks, Pandas, Scikit-learn, Transformers, SpaCy, Optuna, Ollama.

## Результаты

Модель на основе LLM показала лучшие результаты по сравнению с моделью BERT по всем метрикам. Однако дообучение модели LLM может быть более ресурсоемким.


## Автор

Автор: Заводов Андрей [GitHub](https://github.com/SleekVortex)
